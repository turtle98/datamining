{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/turtle98/datamining/blob/main/takehomeexam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "9uKHvEWKug2y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa21daf7-ba75-41ae-95e7-821970de8c9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# !pip install IPython\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ST-Gvrzug29"
      },
      "source": [
        "## 1. 모듈 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "hY4VDh9Nug2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64c4978c-e44d-4e34-c658-4569e85a743b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: chefboost in /usr/local/lib/python3.10/dist-packages (0.0.17)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from chefboost) (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from chefboost) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from chefboost) (4.65.0)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from chefboost) (5.9.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.22.0->chefboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.22.0->chefboost) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.22.0->chefboost) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "''' 기본 모듈 및 시각화 모듈 '''\n",
        "from IPython.display import display, HTML\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import scipy.stats\n",
        "\n",
        "''' 데이터 전처리 모듈 '''\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "\n",
        "''' Neural Network Classifier 모듈 '''\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "''' 결과 평가용 모듈 '''\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.metrics import accuracy_score\n",
        "''' 기타 optional'''\n",
        "import warnings, itertools\n",
        "warnings.filterwarnings(action='ignore')\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "  random.seed(seed)\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "  np.random.seed(seed)\n",
        "  print('done')\n"
      ],
      "metadata": {
        "id": "8PpaIC-Q6EXb"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_everything(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2fctd8s6Fa_",
        "outputId": "f0c7c596-ea5d-42e0-eece-2d3108c28aa3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tG8-TIThug3D"
      },
      "source": [
        "### 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "nEve46Xhug3E"
      },
      "outputs": [],
      "source": [
        "df1 = pd.read_csv('/content/drive/MyDrive/bada/train_data.csv', delimiter = ',')\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/bada/test_data.csv', delimiter = ',')\n",
        "df3 = pd.read_csv('/content/drive/MyDrive/bada/adult.csv', delimiter = ',')\n",
        "df4 = pd.read_csv('/content/drive/MyDrive/bada/abalone_original.csv', delimiter = ',')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "yCqDLKofug3H"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([df1,df2])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classifier 만들기**"
      ],
      "metadata": {
        "id": "SwqH2enDRvDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_mlp(df):\n",
        "  #df를 독립변수 X와 종속 변수 Y로 분리시키자\n",
        "  if df.shape[1] == 9:\n",
        "      X = df.iloc[:,1:]\n",
        "      y = df.iloc[:,0]\n",
        "      train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.5, random_state=42)\n",
        "      return train_x, test_x, train_y, test_y\n",
        "  X = df.iloc[:,:-1]\n",
        "  y = df.iloc[:,-1]\n",
        "  train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.5, random_state=42)\n",
        "  return train_x, test_x, train_y, test_y\n",
        "\n",
        "class mlp_clf:\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "        #데이터 전처리\n",
        "        self.train_x, self.test_x, self.train_y, self.test_y = self.getdata()\n",
        "        self.modelA = self.getmodel_A()\n",
        "        self.modelB = self.getmodel_B()\n",
        "\n",
        "    def getdata(self):\n",
        "        train_x, test_x, train_y, test_y = pre_mlp(self.df)\n",
        "        train_x = pd.get_dummies(train_x, drop_first = True)\n",
        "        test_x = pd.get_dummies(test_x, drop_first = True)\n",
        "        test_x = test_x.reindex(columns = train_x.columns, fill_value=0)\n",
        "        le = preprocessing.LabelEncoder()\n",
        "        train_y=le.fit_transform(train_y)\n",
        "        test_y=le.transform(test_y)\n",
        "    \n",
        "        return train_x, test_x, train_y, test_y\n",
        "    \n",
        "    def getmodel_A(self):\n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(self.train_x)\n",
        "        self.train_x = scaler.transform(self.train_x)\n",
        "        self.test_x = scaler.transform(self.test_x)\n",
        "        parameter_space = {\n",
        "        'hidden_layer_sizes': [(5,3), (30,15), (50,25)],\n",
        "        'momentum': [0.9, 0.99],\n",
        "        'alpha': [0.01, 0.03],\n",
        "        'max_iter': [100,300]\n",
        "        }\n",
        "        model = MLPClassifier(batch_size=self.train_x.shape[0], solver = 'adam', activation='relu', random_state = 42)\n",
        "        clf = GridSearchCV(model, parameter_space, n_jobs=-1, cv=2)\n",
        "        best_model = clf.fit(self.train_x, self.train_y)\n",
        "        return best_model\n",
        "\n",
        "    def getmodel_B(self):\n",
        "        scaler = StandardScaler()\n",
        "        scaler.fit(self.test_x)\n",
        "        self.test_x = scaler.transform(self.test_x)\n",
        "        self.train_x = scaler.transform(self.train_x)\n",
        "        parameter_space = {\n",
        "        'hidden_layer_sizes': [(5,3), (30,15), (50,25)],\n",
        "        'momentum': [0.9, 0.99],\n",
        "        'alpha': [0.01, 0.03],\n",
        "        'max_iter': [100,300]\n",
        "        }\n",
        "        model = MLPClassifier(batch_size=self.test_x.shape[0], solver = 'adam', activation='relu', random_state = 42)\n",
        "        clf = GridSearchCV(model, parameter_space, n_jobs=-1, cv=2)\n",
        "        best_model = clf.fit(self.test_x, self.test_y)\n",
        "        return best_model\n",
        "\n",
        "    def bestparams(self):\n",
        "        return self.modelA.best_params_, self.modelB.best_params_\n",
        "\n",
        "\n",
        "    def predict(self):\n",
        "        y_pred_A = self.modelA.predict(self.test_x)\n",
        "        y_pred_B = self.modelB.predict(self.train_x)\n",
        "        predictions_A = [round(value) for value in y_pred_A]\n",
        "        predictions_B = [round(value) for value in y_pred_B]\n",
        "        confidence = 0.95  \n",
        "        z_value = scipy.stats.norm.ppf((1 + confidence) / 2.0)\n",
        "        # 평가하기\n",
        "        accuracy_A = accuracy_score(self.test_y, predictions_A)\n",
        "        accuracy_B = accuracy_score(self.train_y, predictions_B)\n",
        "        ci_length_A = z_value * np.sqrt((accuracy_A* (1 - accuracy_A)) / self.test_y.shape[0])\n",
        "        ci_lower_A = (1-accuracy_A) - ci_length_A\n",
        "        ci_upper_A = (1-accuracy_A) + ci_length_A\n",
        "        ci_length_B = z_value * np.sqrt((accuracy_B* (1 - accuracy_B)) / self.train_y.shape[0])\n",
        "        ci_lower_B = (1-accuracy_B) - ci_length_B\n",
        "        ci_upper_B = (1-accuracy_B) + ci_length_B\n",
        "        #av_err = ((1-accuracy_A) + (1-accuracy_B))/2\n",
        "        #std_err = z_value * np.sqrt((1-accuracy_A-av_err)^2 + (1-accuracy_B-av_err)^2)\n",
        "        #ci_lower_av = av_err - std_err\n",
        "        #ci_upper_av = av_err + std_err\n",
        "        #print('Accuracy trained on A : %.2f%%'%(accuracy_A*100))\n",
        "        #print('Accuracy trained on B : %.2f%%'%(accuracy_B*100))\n",
        "        #print('Average Accuracy : %.2f%%'%((accuracy_B*100 + accuracy_B*100)/2))\n",
        "        print('error trained on A : %.2f%%'%((1-accuracy_A)*100))\n",
        "        print('error trained on B : %.2f%%'%((1-accuracy_B)*100))\n",
        "        print('Average error : %.2f%%'%(((1-accuracy_B)*100 + (1-accuracy_B)*100)/2))\n",
        "        #print(f'lower & upper confidence interval of Average error : {ci_lower_av, ci_upper_av}')\n",
        "        print(f'lower & upper confidence interval on A: {ci_lower_A, ci_upper_A}')\n",
        "        print(f'lower & upper confidence interval on B: {ci_lower_B, ci_upper_B}')\n",
        "\n"
      ],
      "metadata": {
        "id": "hLM6ci2Kyyjy"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## decision tree \n",
        "class DT:\n",
        "  def __init__(self, df):\n",
        "        self.df = df\n",
        "        #데이터 전처리\n",
        "        self.train_x, self.test_x, self.train_y, self.test_y = self.getdata()\n",
        "        self.modelA = self.getmodel_A()\n",
        "        self.modelB = self.getmodel_B()\n",
        "\n",
        "  def getdata(self):\n",
        "        train_x, test_x, train_y, test_y = pre_mlp(self.df)\n",
        "        train_x = pd.get_dummies(train_x, drop_first = True)\n",
        "        test_x = pd.get_dummies(test_x, drop_first = True)\n",
        "        test_x = test_x.reindex(columns = train_x.columns, fill_value=0)\n",
        "        le = preprocessing.LabelEncoder()\n",
        "        train_y=le.fit_transform(train_y)\n",
        "        test_y=le.transform(test_y)\n",
        "    \n",
        "        return train_x, test_x, train_y, test_y      \n",
        "\n",
        "  def getmodel_A(self):\n",
        "        model = DecisionTreeClassifier(random_state = 42)\n",
        "        best_model = model.fit(self.train_x, self.train_y)\n",
        "        return best_model\n",
        "        \n",
        "  def getmodel_B(self):\n",
        "        model = DecisionTreeClassifier(random_state = 42)\n",
        "        best_model = model.fit(self.test_x, self.test_y)\n",
        "        return best_model\n",
        "        \n",
        "  def predict(self):\n",
        "        y_pred_A = self.modelA.predict(self.test_x)\n",
        "        y_pred_B = self.modelB.predict(self.train_x)\n",
        "        predictions_A = [round(value) for value in y_pred_A]\n",
        "        predictions_B = [round(value) for value in y_pred_B]\n",
        "        confidence = 0.95  \n",
        "        z_value = scipy.stats.norm.ppf((1 + confidence) / 2.0)\n",
        "        # 평가하기\n",
        "        accuracy_A = accuracy_score(self.test_y, predictions_A)\n",
        "        accuracy_B = accuracy_score(self.train_y, predictions_B)\n",
        "        ci_length_A = z_value * np.sqrt((accuracy_A* (1 - accuracy_A)) / self.test_y.shape[0])\n",
        "        ci_lower_A = (1-accuracy_A) - ci_length_A\n",
        "        ci_upper_A = (1-accuracy_A) + ci_length_A\n",
        "        ci_length_B = z_value * np.sqrt((accuracy_B* (1 - accuracy_B)) / self.train_y.shape[0])\n",
        "        ci_lower_B = (1-accuracy_B) - ci_length_B\n",
        "        ci_upper_B = (1-accuracy_B) + ci_length_B\n",
        "        #av_err = ((1-accuracy_A) + (1-accuracy_B))/2\n",
        "        #std_err = z_value * np.sqrt((1-accuracy_A-av_err)^2 + (1-accuracy_B-av_err)^2)\n",
        "        #ci_lower_av = av_err - std_err\n",
        "        #ci_upper_av = av_err + std_err\n",
        "        #print('Accuracy trained on A : %.2f%%'%(accuracy_A*100))\n",
        "        #print('Accuracy trained on B : %.2f%%'%(accuracy_B*100))\n",
        "        #print('Average Accuracy : %.2f%%'%((accuracy_B*100 + accuracy_B*100)/2))\n",
        "        print('error trained on A : %.2f%%'%((1-accuracy_A)*100))\n",
        "        print('error trained on B : %.2f%%'%((1-accuracy_B)*100))\n",
        "        print('Average error : %.2f%%'%(((1-accuracy_B)*100 + (1-accuracy_B)*100)/2))\n",
        "        #print(f'lower & upper confidence interval of Average error : {ci_lower_av, ci_upper_av}')\n",
        "        print(f'lower & upper confidence interval on A: {ci_lower_A, ci_upper_A}')\n",
        "        print(f'lower & upper confidence interval on B: {ci_lower_B, ci_upper_B}')\n",
        "\n"
      ],
      "metadata": {
        "id": "j9msbDRc94m8"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DT(df)\n",
        "dt.predict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLQuCCCtBZZG",
        "outputId": "b4ab96c0-5a0b-4f49-8023-c86e766e82e9"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error trained on A : 12.69%\n",
            "error trained on B : 12.71%\n",
            "Average error : 12.71%\n",
            "lower & upper confidence interval on A: (0.12257392212706797, 0.13125249563812702)\n",
            "lower & upper confidence interval on B: (0.12271013429380188, 0.13139294024722875)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt1 = DT(df3)\n",
        "dt1.predict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3UrKsjQEHD7",
        "outputId": "b52321f5-1c0c-4ac2-c3c9-1023f72a2185"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error trained on A : 18.23%\n",
            "error trained on B : 18.89%\n",
            "Average error : 18.89%\n",
            "lower & upper confidence interval on A: (0.1774597393192417, 0.1871444947416076)\n",
            "lower & upper confidence interval on B: (0.18394501558155127, 0.19376269499541113)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dt2 = DT(df4)\n",
        "dt2.predict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wsjOEPCEqEP",
        "outputId": "47236ff1-05dd-41c8-a969-5238d101785a"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error trained on A : 49.69%\n",
            "error trained on B : 53.02%\n",
            "Average error : 53.02%\n",
            "lower & upper confidence interval on A: (0.47544768904748214, 0.5183292377117328)\n",
            "lower & upper confidence interval on B: (0.5087651745019826, 0.5515796530842243)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## banking dataset\n",
        "mlp= mlp_clf(df)\n",
        "mlp.predict()\n",
        "mlp.bestparams()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsCv797E6DDg",
        "outputId": "5200a7c7-add6-4b58-f8f1-80ac16438ba6"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error trained on A : 10.00%\n",
            "error trained on B : 9.80%\n",
            "Average error : 9.80%\n",
            "lower & upper confidence interval on A: (0.09610666003065865, 0.10392872880416387)\n",
            "lower & upper confidence interval on B: (0.09411159012248577, 0.10186275183725774)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'alpha': 0.03,\n",
              "  'hidden_layer_sizes': (30, 15),\n",
              "  'max_iter': 300,\n",
              "  'momentum': 0.9},\n",
              " {'alpha': 0.01,\n",
              "  'hidden_layer_sizes': (50, 25),\n",
              "  'max_iter': 300,\n",
              "  'momentum': 0.9})"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#adult\n",
        "mlp1 = mlp_clf(df3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0adpDxOInk1x",
        "outputId": "a9d18675-e1cb-479f-dc58-2817612b40c9"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error trained on A : 14.93%\n",
            "error trained on B : 15.09%\n",
            "Average error : 15.09%\n",
            "lower & upper confidence interval on A: (0.14482800057222783, 0.15376747053870127)\n",
            "lower & upper confidence interval on B: (0.14636491711799832, 0.15534262966550766)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp1.predict()\n",
        "mlp1.bestparams()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClfCTJ5L9IcI",
        "outputId": "c0c76e4d-bcda-487b-8690-a60c5317d555"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error trained on A : 14.93%\n",
            "error trained on B : 15.09%\n",
            "Average error : 15.09%\n",
            "lower & upper confidence interval on A: (0.14482800057222783, 0.15376747053870127)\n",
            "lower & upper confidence interval on B: (0.14636491711799832, 0.15534262966550766)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'alpha': 0.01,\n",
              "  'hidden_layer_sizes': (50, 25),\n",
              "  'max_iter': 300,\n",
              "  'momentum': 0.9},\n",
              " {'alpha': 0.03,\n",
              "  'hidden_layer_sizes': (50, 25),\n",
              "  'max_iter': 300,\n",
              "  'momentum': 0.9})"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp2 = mlp_clf(df4)\n",
        "mlp2.predict()\n",
        "mlp2.bestparams()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdyao2WAENtw",
        "outputId": "34ffedf4-467f-4274-ed4e-837bf25234f9"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error trained on A : 42.32%\n",
            "error trained on B : 42.58%\n",
            "Average error : 42.58%\n",
            "lower & upper confidence interval on A: (0.4019824379499029, 0.4443555227968658)\n",
            "lower & upper confidence interval on B: (0.40455764346626233, 0.44697492358354607)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'alpha': 0.01,\n",
              "  'hidden_layer_sizes': (50, 25),\n",
              "  'max_iter': 300,\n",
              "  'momentum': 0.9},\n",
              " {'alpha': 0.03,\n",
              "  'hidden_layer_sizes': (30, 15),\n",
              "  'max_iter': 300,\n",
              "  'momentum': 0.9})"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#comparing performance of two algorithmns\n",
        "#Banking data set\n",
        "d_1 = (12.69-10)\n",
        "d_2 = (12.71-9.8)\n",
        "d_bar = (d_1+d_2)/2\n",
        "samp_var_d = (d_1-d_bar)**2 +(d_2-d_bar)**2 \n",
        "\n",
        "#95% confidence for true difference d_t\n",
        "d_t_upper  = d_bar + 6.314*np.sqrt((samp_var_d)/2)\n",
        "d_t_lower  = d_bar - 6.314*np.sqrt((samp_var_d)/2)\n",
        "\n",
        "print(d_t_upper)\n",
        "print(d_t_lower)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCGQk3x_Hprf",
        "outputId": "1d3b2e61-ee39-42ef-9c02-46f333987c4b"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.494540000000002\n",
            "2.1054599999999977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#comparing performance of two algorithmns\n",
        "#Adult data set\n",
        "d_1 = (18.23-14.93)\n",
        "d_2 = (18.89-15.09)\n",
        "d_bar = (d_1+d_2)/2\n",
        "samp_var_d = (d_1-d_bar)**2 +(d_2-d_bar)**2 \n",
        "\n",
        "#95% confidence for true difference d_t\n",
        "d_t_upper  = d_bar + 6.314*np.sqrt((samp_var_d)/2)\n",
        "d_t_lower  = d_bar - 6.314*np.sqrt((samp_var_d)/2)\n",
        "\n",
        "print(d_t_upper)\n",
        "print(d_t_lower)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cB6vX7pJiKh",
        "outputId": "d1f37bc3-1f1f-4633-d53e-988262fbeda0"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.128500000000001\n",
            "1.9715000000000007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#comparing performance of two algorithmns\n",
        "#Abalone data set\n",
        "d_1 = (49.69-42.32)\n",
        "d_2 = (53.02-42.58)\n",
        "d_bar = (d_1+d_2)/2\n",
        "samp_var_d = (d_1-d_bar)**2 +(d_2-d_bar)**2 \n",
        "\n",
        "#95% confidence for true difference d_t\n",
        "d_t_upper  = d_bar + 6.314*np.sqrt((samp_var_d)/2)\n",
        "d_t_lower  = d_bar - 6.314*np.sqrt((samp_var_d)/2)\n",
        "\n",
        "print(d_t_upper)\n",
        "print(d_t_lower)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49avXIT0NEkd",
        "outputId": "cc447710-291a-46f4-e969-a162d197bb3c"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18.596990000000027\n",
            "-0.7869900000000225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "/content/drive/MyDrive/Colab Notebooks/takehomeexam.ipynb"
      ],
      "metadata": {
        "id": "17pfS-y6S9Y4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ttest3.8",
      "language": "python",
      "name": "ttest3.8"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}